{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db75357f-87aa-4e10-ba37-d10a5d0f89cf",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "You will be using the Diabetes dataset from sklearn for all your Regression tasks\n",
    "\n",
    "Get the dataset using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0291850a-8c25-4ea5-9663-be3c9b3809aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes_df =  load_diabetes(as_frame=True).frame\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8d228-c077-4eec-8fd5-18b6fbe2d6fa",
   "metadata": {},
   "source": [
    "Your objectives are available in the README.md file accompanying this notebook:\n",
    "\n",
    "I will be providing a jupyter file with headers for where you can insert your answers for each question\n",
    "\n",
    "Below we will be going over the following to help you with the Lab:\n",
    "- How to create a ***correlation matrix***\n",
    "- How to select the best k features using ***pearsons correlation***\n",
    "  - How to show which features were selected with pearsons correlation\n",
    "- How to do ***forward selection***\n",
    "  - How to show which features were selected with forward selection\n",
    "- How to do ***backward elimination***\n",
    "  - Showing how features are selected is the same as withforward selection \n",
    "- How to do ***recursive feature Elimination***\n",
    "  - How to show which features were selected\n",
    "  - How to show ranking of features\n",
    "- How to do ***cross validation*** with ***ShuffleSplit***\n",
    "- How to use ***RidgeCV*** to find the best regularization ***parameter/alpha***\n",
    "  - How to grab the best alpha from RidgeCV\n",
    "- How to use ***Regularized Linear Regression/Ridge Regression***\n",
    "- How to plot a ***learning curve***\n",
    "- How to do ***LassoCV Regression*** \n",
    "  - How to grab features that have been selected\n",
    "- How to do regular ***LassoRegression*** \n",
    "\n",
    "***Note:*** I will not be going over the LinearRegression class as it is covered in the previous Lab <br>\n",
    "***Note*** I will not be going over rsquared and mse as thety are covered in the previous lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920ab12-07d4-4201-9ab2-0fbbd9096c28",
   "metadata": {},
   "source": [
    "## Below is our sample data for our demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50acf265-a6eb-4cb7-9b82-6b0271e28510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4    y\n",
       "0   1   1   4   8   90\n",
       "1   1   2   3   4   57\n",
       "2   2   2   9   9  135\n",
       "3   2   3   4   4   67\n",
       "4   2   0   3   4   54\n",
       "5   2   6   7   4   94\n",
       "6   1   3   6   4   80"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = np.array([[1, 1, 4, 8], [1, 2, 3, 4], [2, 2, 9, 9], [2, 3, 4, 4], [2, 0, 3, 4], [2, 6, 7, 4], [1, 3, 6, 4]])\n",
    "# y = 1 * x_1 + 2 * x_2 + 3\n",
    "y = np.dot(X, np.array([1, 2, 7, 7])) + 3\n",
    "X_y_df = pd.DataFrame(np.array(np.transpose([X[:,0], X[:,1], X[:,2], X[:,3], y])), columns=[\"x1\", \"x2\", \"x3\", \"x4\", \"y\"])\n",
    "X_y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b029a19d-3925-4eac-b4e6-649d45c55668",
   "metadata": {},
   "source": [
    "## How to create a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d4b616-75b2-43d8-829a-a3f4711e2e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAJCCAYAAABztidJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABCEklEQVR4nO3deZyVdf3//8frDPsmIJsbbgGK4pJrKm6okVq4b20W/TSXzI+f9JulmfpJk7Qs0wzTNMPccs0tczekxA0VFXEB2UFABkFh5rx/f8wIM6zjG2bOzPC4327n5jnX9Z45r3Muz8yL5/t9XRMpJSRJkqTPq1DqAiRJktQ02UhKkiQpi42kJEmSsthISpIkKYuNpCRJkrLYSEqSJCmLjaQkSVIzEBE3RMSMiHhtJfsjIn4XEeMjYkxEfHFNn9NGUpIkqXm4ERi8iv1fAfpU304C/rCmT2gjKUmS1AyklJ4GZq9iyBDgL6nKKKBzRGywJs/ZYk2+uC6+H5380zlNxNW/+lapS1AdpYkTS12CPoc49sRSl6C6evqRUlegOio7949R6hoausf5I+UnU5UkfmZ4Smn45/gWGwEf1Hg8qXrb1Nya6r2RlCRJ0pqrbho/T+NY72wkJUmSMjTB9YGTgU1qPN64elu2JvgeSJIkKcN9wLeqz97eHfgopZQ9rQ0mkpIkSVkKUfJlmrVExN+AfYFuETEJuABoCZBSuhZ4EDgYGA8sAL6zps9pIylJktQMpJSOX83+BJy2Np/TqW1JkiRlMZGUJEnKYBrneyBJkqRMJpKSJEkZCo3rXJuSMJGUJElSFhNJSZKkDKZxvgeSJEnKZCIpSZKUobFdkLwUTCQlSZKUxURSkiQpg2mc74EkSZIymUhKkiRl8DqSJpKSJEnKZCIpSZKUwTTO90CSJEmZTCQlSZIyhNeRNJGUJElSHhtJSZIkZXFqW5IkKYNpnO+BJEmSMplISpIkZfCC5CaSkiRJymQiKUmSlME0zvdAkiRJmUwkJUmSMhS8ILmJpCRJkvKYSEqSJGUwjfM9kCRJUiYTSUmSpAxeR9JEUpIkSZlMJCVJkjKYxvkeSJIkKZOJpCRJUoYCLpI0kZQkSVIWG0lJkiRlcWpbkiQpg5f/MZGUJElSJhNJSZKkDKZxvgeSJEnKZCIpSZKUwTWSJpKSJEnKZCIpSZKUwQuSm0hKkiQpk4mkJElSBtdImkhKkiQpk4nk5/TN669mwKGDKZ8xk4sH7F7qctZtm21NYf+jIAqkV0eS/vtord2x0/7Edl+CYhEWzKf4yF9h3hwACkeeChtsBpPfpXj3tSUoft0TW3+RwhHfg0IZxef+SfrX32vv33MwhYEHVx2vTz+h8rarYdoH0LsPZcedVj0oKD70N9KYUSV4BeuOlBKX3HI/T7/6Fm1bteKSoUfRf9ONlhv3+vuT+cn1d/DJ4sXsPaAfPznhq0QEv7r9QZ58+U1atihjk+5d+cXQo+jUrm0JXsk6YIttKBxwDBQKpJefJY16pNbu2OUAYoc9l/4cfOAmmDcbOnWlcOQpEAGFMtILT5BeerpEL6LpMo3LbCQj4sCU0qOrH9n8PHfjCJ78/XBO/MsfS13Kui2CwgHHULzj91A+l8I3zia98yp8OG3JkDTjA9LNz0DFYmL7vYi9DyP9488AFJ//F7RoRWH7vUr1CtYtUaBw9MlUXv0zmPshZT+6gsrX/lvVKFZLLzxF5b8frhq+7a4UDh9K8Q8/h6kTqLz8rKpfhJ26UPb/flv1tcViiV5M8/f0q28xYfqHPHzpjxjz7gdc+Jd7uO3805Ybd9HN93DRiUew3RabcPJvbuSZV8ex93b92KP/F/ifI79Mi7IyrrjjIa574En+9+ivlOCVNHMRFA46nuKtV8K8ORROPJf09hj4cOqSIWn6RNKfn6r6Objj3sR+R5LuvQ7mf0TxL5dBZQW0bE3hez8jvf0KzP+odK9HTVJuM339Wq2iCRn/zEgWzJ5T6jLUazOYMws++hCKlaQ3XyS23K72mA/ehorFAKSp7xMdOy/dN3EcLP60wcpd523ahzRzKnw4HSorKL74DDFgt9pjPlm49H6rNpBS1f3Fi5Y2jS1aQWqYktdlj7/0BkP22JGIYPste1O+4BNmzp1Xa8zMufOYv/BTtt+yNxHBkD125LGXxgKw57Z9aVFWBsD2W/Rm2hybk3qx4eYwZwbMnVX1c/CN0UTf7WuPmThu6c/BKe8RnTpXbS9WVjWRAC1aQJit5ShEw94ao5UmkhFx38p2AevXTzlSHXVcj1Reo6GfP6dqqnolYsCXSO+Nrf+6tELRef2qX3afmTuL2LTfcj1hDDyYwn5DoKwFlb8/b+mOTftSdsIZ0LU7xZt/YxpZz2bM+YheXTsvedyz63pMnzOP7p07Ldk2fc48enbpVGvMjBU0jHc9O5rBu2633HatBR06k+bV+DlYPqequVyJ2H5P0juvL93QsQuFY06HLj1Ij//dNFJZVjW1PRD4BjB/me0B7LqqbxoRJwEnVX2T1vSn1ZrUKK2R2HoXomdvirf9ttSlaDXSMw9S+cyDxE57UzjoWIojrqzaMWEclZeeDj03puwbZ1I59oUlKYsar2vvf4KyQoGv7r5DqUtZ58U2uxG9NqU44oqlG8vnULz+YuiwHoUjTyG9+QIsKC9dkU2Q15FcdSM5CliQUnpq2R0R8daqvmlKaTgwHOD70cmJKK195R8RHbssTbQ6dIHyFfxrunc/YvcvU7ztyqXTOGpwae6HROduSzd07kb66MOVj3/xGQrHnAIjltkxfRLp009gg03hg/H1U+w66pbHnuOOp58HYMDmGzNt9twl+6bP/qhW+gjQs0snps+ZV2tMjy7rLXl897Mv8NSYN7jhR98jwl+29WL+XKJTjZ+DHbtA+dzlx222FbHHV6qayBX9HJz/EWnmFNikD7z1Yj0WrOZopYsiUkpfSSk9ERH9V7D7Z/VYk7R60yZAl+6w3vpQKCO2+iLpnTG1x/TYmMJBx1G8+4+wYNlgXQ1q4ttE9w2ha08oa0HhiwNJr/6n9pjuGyy5G9vsDDOnVD3o2hMK1T+qunQnem4Es6c3UOHrjhMGfYm7LzyDuy88g0E79ufekS+RUuKVdybSsV2bWtPaAN07d6JD29a88s5EUkrcO/Il9t9xawCeefUtrn/oaa7+wbdo29oZqXoz5X3o0mPpz8Gtd646YaamnptQGPwNindeUztt7NgZWrSsut+mHbHJF2D2NKTPqy5nbd8eETcDw4A21f/dGfhSfRbWWA295Qb67rsXHbqtz6UfvMH9F1zCyBtuLnVZ655UpPjY7RSOPA0KQXp1FHw4jdjzENK0ifDOqxT2OazqbMSvDa36mnlzKN5TdbZ94bgzqxqUlq0pnHwxxUdugfffKNnLafaKRYp3/pGyU38OhQLFUf+CaR9QOPgE0sTxpNf+S2HgIUS/HaCygrRwPpV/vRKA2HJrCgecX5WkpETx9mvhY6ff6tPe2/Xj6TFvMfjHl9OmVUt+8d2jluw7/ILfcfeFZwBw/jeG8JMb7uTTRYsZOKAvew/oB8D/jbiPxYsrGXrFDQBsv+Um/Pxbhzf8C2nuUpHio7dSOO6HVZdBG/NvmDWVGPhV0tQJMH4Mhf2OhFatKRx+UtXXzJtd1VSuvwGFQUdVndQWQfrPo0v/8aY6a6wnwDSkSGnVM88R0R64DNgJ6EjVZNNlKaU6rXZ3arvpuPpX3yp1CaqjNHFiqUvQ5xDHnljqElRXTz+y+jFqFMrO/WPJ27jrO3Vv0B5n6LyZJX/Ny6pLIrkYWAi0pSqRfK+uTaQkSVJz1ei6uhKoy4WjnqeqkdyFqjO5j4+IO+q1KkmSJDV6dUkkh6aURlffnwoMiYhv1mNNkiRJjZ5rJOuQSNZoImtu8+wSSZKkdVzW39qWJEla13lB8vy/tS1JkqR1nImkJElSBtdImkhKkiQpk4mkJElSBtM43wNJkiRlMpGUJEnK4BJJE0lJkiRlMpGUJEnKUAgzSRNJSZIkZbGRlCRJUhantiVJkjI4sW0iKUmSpEwmkpIkSRlMJE0kJUmSlMlEUpIkKYOJpImkJElSsxARgyPirYgYHxE/XsH+3hHxRES8FBFjIuLgNX1OE0lJkqQM0YguSB4RZcDVwIHAJOD5iLgvpTS2xrDzgNtTSn+IiP7Ag8Bma/K8JpKSJElN367A+JTSuymlRcCtwJBlxiSgU/X99YApa/qkJpKSJEkZGjqPjIiTgJNqbBqeUhpefX8j4IMa+yYBuy3zLX4O/DMifgC0Bw5Y05psJCVJkpqA6qZx+GoHrtzxwI0ppSsi4kvAzRGxbUqpmPsNbSQlSZIyNLL1gZOBTWo83rh6W01DgcEAKaXnIqIN0A2Ykfukjew9kCRJUobngT4RsXlEtAKOA+5bZsxEYBBARGwNtAFmrsmTmkhKkiRlaEQnbZNSqoiI04FHgDLghpTS6xFxETA6pXQf8L/AdRHxP1SdeHNiSimtyfPaSEqSJDUDKaUHqbqkT81tP6txfyyw59p8ThtJSZKkDOHftnGNpCRJkvLYSEqSJCmLU9uSJEkZnNg2kZQkSVImE0lJkqQMJpImkpIkScpkIilJkpShYCRpIilJkqQ8JpKSJEkZvCC5iaQkSZIymUhKkiRlMI80kZQkSVImE0lJkqQMYSRpIilJkqQ8JpKSJEkZDCRNJCVJkpTJRFKSJClDwUzSRFKSJEl5TCQlSZIymEc2QCN59a++Vd9PobXktLP/UuoSVEfD9tuy1CXoc+j0y0GlLkF1VPn4A6UuQWpSnNqWJElSFqe2JUmSMnhBchNJSZIkZTKRlCRJymAgaSIpSZKkTCaSkiRJGcJM0kRSkiRJeUwkJUmSMhQMJE0kJUmSlMdEUpIkKYOBpImkJEmSMplISpIkZTCRNJGUJElSJhNJSZKkDF5H0kRSkiRJmUwkJUmSMoSBpImkJEmS8thISpIkKYtT25IkSRlM43wPJEmSlMlEUpIkKYPn2phISpIkKZOJpCRJUobw+j8mkpIkScpjIilJkpTBPNJEUpIkSZlMJCVJkjKYSJpISpIkKZOJpCRJUgbP2jaRlCRJUiYTSUmSpAwFA0kTSUmSJOUxkZQkScoQRpImkpIkScpjIylJkqQsTm1LkiRl8Oo/JpKSJEnKZCIpSZKUwUTSRFKSJEmZTCQlSZIy+CcSTSQlSZKUyURSkiQpg4GkiaQkSZIymUhKkiRlcI2kiaQkSZIymUhKkiRlMJA0kZQkSVImE0lJkqQMBSNJE0lJkiTlMZFc1mZbU9j/KIgC6dWRpP8+Wmt37LQ/sd2XoFiEBfMpPvJXmDcHgMKRp8IGm8HkdynefW0JildN37z+agYcOpjyGTO5eMDupS5nnVe2yx60Of1solBg0YP3sOhvf17huBYDB9HuwsuZ//2vUxw3Flq0oM1Z51HWtz+kxCe/H0blKy80cPXrlpQSvxh2BU/9eyRt2rThlxf+jG223mq5cUNPO4OZM2dRWVnJTjvuwAXnnkNZWRkPPfovfn/tdbzz3vvccfOfGbBN/xK8inXElttS+PLxEEF66RnSyIdq7Y7dDiJ2HAjFyqrfWff/GT76cOmAVm0onHIx6a2XSA/f0sDFN30GkqtJJCOiU0RsuYLt29VfSSUUQeGAYyj+/RqKf/4/YqudYP1etYakGR9QvHkYxZsuJY17idj7sCX7is//i+KDf2ngorUyz904gqsGH1HqMgRQKND2hz9mwY9PZ/53jqTl/oMpbLrF8uPatqPVkSdQMXbMkk0tD6k6hh9/7xgWnP192pxylj+969nTz47k/Ykf8M97/87F553Lzy+5bIXjfnvZJdx3+y38485bmTNnLg8/+hgAfbfckquuGMYuX9yxIcte90RQGPx1irf8huIfzie23Q26bVBrSJo2geKfLqY4/OekN0YTg46q/S32PZw0cVwDFq3mZqWNZEQcA7wJ/D0iXo+IXWrsvrG+CyuJXpvBnFlV/1orVpLefJHYcpme+YO3oWIxAGnq+0THzkv3TRwHiz9tsHK1auOfGcmC2XNKXYaAsq22pTj5A9LUyVBRweLHH6HFHvsuN671d0+tSioXLVr6tZtuQeVLzwOQ5s4hzS+n0M+Eqz499tTTHHbowUQEO2w3gHnl5cyYOWu5cR06dACgoqKSxRWLl1xTb8stNmeLzTZt0JrXSRtuAXNmwNxZVb+zXv8v0W+Z5n3CW1BR9XlKk98lOnVZuq/XptChE7wztgGLVnOzqkTyJ8BOKaUdgO8AN0fE4dX7mmcc0HE9UnmNxmP+HOi43kqHx4Avkd7zAyitTnTrQXHG9CWP06zpFLp3rzWm0GcrCt17UfGfZ2ttr3xnHC322AcKZUSvDSnr259C99ozBVq7ps+YQa9ePZc87tWzB9NnzFjh2KGn/oA9Bn2Z9u3a8eUD9m+oEgXQqTNp3uylj+fNgZrhxjJih71I41/77BGFA48hPXp7vZbY3EVEg94ao1U1kmUppakAKaX/AvsB50XEGUBa1TeNiJMiYnREjL5u1Otrr9pGJLbehejZm/T8Y6UuRWr6Imhzyv/yyR+uWG7X4ofupThzOu2vHUGb086m4vVXqtZ7qVG4/pqrePbRB1m0aDGjnh9d6nK0EjFgd2KDzUjPPVz1eOf9SONfhXJnbZqTiBgcEW9FxPiI+PFKxhwTEWOrZ5vXeGHsqk62KY+ILVNK7wCklKZGxL7APcA2q/qmKaXhwHCAystPX2XT2aiUf0R07LK0S+7QBco/Wn5c737E7l+meNuVUFnRgAVKTVOaNYNCj6UJV3TrSXHmzKUD2rWnsPmWtP/Nn6r2d12fdv93JQvOO5PiuLF8es0VfLZopN1VN1KcNLEBq183jLjtDm6/6x4ABmzTn2nTlibI06bPoGePHiv92tatWzNo37157Mmn2XP33eq7VH1m3lyiU9elv7M6dYHyucuP23xrYq9DKN40bOnvrI23JHr3IXbeD1q1hrIWsOhT0uN/b6Dim4doRNe+iYgy4GrgQGAS8HxE3JdSGltjTB/gXGDPlNKciFj5B7uOVtVIngIUIqL/Z0WklMojYjBw3Jo+caM0bQJ06Q7rrQ/lc4mtvkjxgRtrj+mxMYWDjqN45zWwYH5JypSamso3X6ewUW+i14akWTNouf+XWfiLc5cO+Hg+8w9fOi3a7tfX8cm1v6k6a7t1m6rFNJ98QtlOu0FlJcUJ7zb8i2jmvn7s0Xz92KMBePKZZ/nrrXdwyOCDeOXV1+jYoQM9unerNf7jBQv4+OMF9OjejYqKCp589t/svOMOJah8HTblPejaEzp3g3lziG12pXj38NpjevWmcPC3KP7tN7CgfMnmdM91SxrQ2G5P2HBTm8imb1dgfErpXYCIuBUYAtRcg/f/AVenlOYApJRWvGblc1hpI5lSeqW6kNci4mZgGNCm+r87Azev6ZM3OqlI8bHbKRx5GhSC9Ooo+HAasechpGkT4Z1XKexzGLRsTeFrQ6u+Zt4civf8EYDCcWdWfahbtqZw8sUUH7kF3n+jZC9nXTf0lhvou+9edOi2Ppd+8Ab3X3AJI29ofv/bNgnFSj656jLaXXYNUVZg0UP3Unz/XVqfeAqV48ZSMfKplX5pdO5Cu2HXQLFImjWThZee14CFr5v22WtPnnp2JAd+7QjatmnDJT8/f8m+Icd+nXtvG8HChQs55cz/ZdHixaRikd123onjjqo6w/7Rx5/g4suuYPacOZx8xlls3a8P119zValeTvOVihQfHkHhhP+pumTdK8/CzCnEPkNIU9+Hca9QGHQ0tGpN4chTqr5m3myKt3ks1paGXrcYEScBJ9XYNLx6FhhgI+CDGvsmActOEfSt/j7/BsqAn6eUHl6jmlJa9cxzRLQHLgN2AjoCI4DLUkrFujxBk5raXseddraXLmoqhu233FW51Ih1+seTpS5BdVR5xVmlLkF1VHb+9SU/+2T81n0atMf5whtvr/Q1R8RRwOCU0veqH38T2C2ldHqNMf8AFgPHABsDTwMDUkpzc2uqywXJFwMLgbZUJZLv1bWJlCRJaq4a2YnUk4FNajzeuHpbTZOA/6SUFgPvRcQ4oA/wfO6T1mWZ6PNUNZK7AAOB4yPijtwnlCRJ0lr3PNAnIjaPiFZUnc9y3zJj7gH2BYiIblRNda/RovO6JJJDU0qfXdNhKjCkOi6VJElaZzWmazumlCoi4nTgEarWP96QUno9Ii4CRqeU7qved1BEjAUqgbNTSh+u/Luu3mobyRpNZM1tnrEgSZLUiKSUHgQeXGbbz2rcT8BZ1be1oi6JpCRJkpbRiALJkmlEl9KUJElSU2IiKUmSlKFgJGkiKUmSpDwmkpIkSRkMJE0kJUmSlMlGUpIkSVmc2pYkScrQmC5IXiomkpIkScpiIilJkpTBQNJEUpIkSZlMJCVJkjKYSJpISpIkKZOJpCRJUoYoGEmaSEqSJCmLiaQkSVIG10iaSEqSJCmTiaQkSVKGgpGkiaQkSZLymEhKkiRlMJA0kZQkSVImE0lJkqQMYSRpIilJkqQ8NpKSJEnK4tS2JElSBme2TSQlSZKUyURSkiQpgyfbmEhKkiQpk4mkJElSBgNJE0lJkiRlMpGUJEnK4BpJE0lJkiRlMpGUJEnKEMZxJpKSJEnKYyIpSZKUwTWSJpKSJEnKZCIpSZKUo2AiaSIpSZKkLCaSkiRJOVwjaSIpSZKkPDaSkiRJyuLUtiRJUgYv/2MiKUmSpEwmkpIkSTm8/I+JpCRJkvKYSEqSJOVwjWT9N5Jp4sT6fgqtJcP227LUJaiOznninVKXoM/hskP2KXUJqqNrRvk7q6k49/zrS12CMJGUJEnKEq6RdI2kJEmS8phISpIk5XCNpImkJEmS8phISpIkZXCNpImkJEmSMplISpIk5XCNpImkJEmS8phISpIk5XCNpImkJEmS8thISpIkKYtT25IkSRnCk21MJCVJkpTHRFKSJCmHJ9uYSEqSJCmPiaQkSVIO10iaSEqSJCmPiaQkSVKGMI4zkZQkSVIeE0lJkqQcrpE0kZQkSVIeE0lJkqQM4XUkTSQlSZKUx0RSkiQph2skTSQlSZKUx0RSkiQph2skTSQlSZKUx0ZSkiSpGYiIwRHxVkSMj4gfr2LckRGRImLnNX1Op7YlSZIyRCM62SYiyoCrgQOBScDzEXFfSmnsMuM6Aj8E/rM2ntdEUpIkqenbFRifUno3pbQIuBUYsoJxFwOXAZ+sjSe1kZQkScpRiAa9RcRJETG6xu2kGtVsBHxQ4/Gk6m1LRMQXgU1SSg+srbfAqW1JkqQmIKU0HBie87URUQB+DZy4NmuykZQkScrRiNZIApOBTWo83rh622c6AtsCT1av7ewF3BcRX0spjc59Uqe2JUmSmr7ngT4RsXlEtAKOA+77bGdK6aOUUreU0mYppc2AUcAaNZFgIilJkpSlMZ21nVKqiIjTgUeAMuCGlNLrEXERMDqldN+qv0MeG0lJkqRmIKX0IPDgMtt+tpKx+66N57SRlCRJyuGfSHSNpCRJkvKYSEqSJGVoTGskS8VEUpIkSVlMJCVJknK4RtJEUpIkSXlMJCVJknK4RtJEUpIkSXlsJCVJkpTFqW1JkqQM4ck2JpKSJEnKYyIpSZKUw5NtTCQlSZKUx0RyGbH1Fykc8T0olFF87p+kf/299v49B1MYeDAUi/DpJ1TedjVM+wB696HsuNOqBwXFh/5GGjOqBK9g3VG2yx60Of1solBg0YP3sOhvf17huBYDB9HuwsuZ//2vUxw3Flq0oM1Z51HWtz+kxCe/H0blKy80cPWq6ZvXX82AQwdTPmMmFw/YvdTlrPNa7LIHbU4/B8oKLH7gbj5d2Wdr70G0v/AK5p98ApXVn622Z51PWb/+kIosvOpXVL4yuoGrX7dsceAgDrj8EgplZbx8482Muvy3tfZ36r0xh1x7Fe26dWPhnDnc/93vUz55CgDH3nsHG+66M5NGjuKOI48vRflNn2skV51IRkSviOhVfb97RBwREds0TGklEAUKR59M5bUXUnnJaRR22ht6bVJrSHrhKSp/eQaVw86k+NhdFA4fWrVj6gQqLz+LymFnUvmHn1M49lQoGPjWm0KBtj/8MQt+fDrzv3MkLfcfTGHTLZYf17YdrY48gYqxY5ZsannIEQB8/L1jWHD292lzyllOT5TYczeO4KrBR5S6DAEUCrT54bl8/OPTmH/iEbQctPLPVusjan+2Wh16JADzhx7Nxz/6Pm1P9bNVn6JQ4KArh3H7kGMYvuOX6H/0kay/Vb9aY/a/9GJeG3Eb1+86kH9f8iv2vej8JftG/eYq7h/6/YYuW83MSjudiDgZeA4YFRGnAP8ADgHuioihDVRfw9q0D2nmVPhwOlRWUHzxGWLAbrXHfLJw6f1WbSClqvuLF1WllAAtWkFqmJLXVWVbbUtx8gekqZOhooLFjz9Ciz32XW5c6++eWpVULlq09Gs33YLKl54HIM2dQ5pfTqFf/4YqXSsw/pmRLJg9p9RliOrP1pTan62We+673Lg23z2NT2+9sdZnq7DpFlS89F9g6WerrF/zzR5KbcNddmLOO+8x9/0JFBcv5o077qLvoV+pNabbVv14/6lnAJjw1DP0OfTgJfsmPPk0i8rnN2jNzU1ENOitMVpVZHY6sA2wE/ArYEhKaSiwO/CDBqitwUXn9WHurKUb5s4i1lt/+XEDD6bsZ3+kMOTbFP8+fOmOTftSdu7vKTv3dxRvv2ZpY6m1Lrr1oDhj+pLHadZ0Ct271xpT6LMVhe69qPjPs7W2V74zjhZ77AOFMqLXhpT17U+he68GqVtq7KJbD9KMaUseF2dOJ7r1qDWm0GcrCj16UjHqmVrbK98ZR8s99q312YoePRui7HVShw03YN6kyUsel0+eQseNNqg1Zsarr9FvyKEA9B1yKK07daRt1y4NWqeat1U1kotTSgtSSh8C76SUpgGklOawmrwtIk6KiNERMfq61yasxXIbh/TMg1RedDLF+26icNCxS3dMGEflpadTefn/UjjwKGjRsnRFrusiaHPK//LJH65Ybtfih+6lOHM67a8dQZvTzqbi9VegWFmCIqUmKIK2p/6Ihdf8erldix+8h+LM6XT44y20Pf1sKl57BSr9B3UpPX7uz+g9cA++89yT9B64J/MmT6FY6c+7taYQDXtrhFZ1sk2KiJYppcVUTWkDEBFtWM3aypTScGA4QMUZX2syk7xp7odE525LN3TuRvrow5WPf/EZCsecAiOW2TF9EunTT2CDTeGD8fVT7DouzZpBoUbSEd16Upw5c+mAdu0pbL4l7X/zp6r9Xden3f9dyYLzzqQ4biyfXnMFn3429KobKU6a2IDVS41XmjWD6LE0oS9070maNWPpgOrPVocra3y2fnElC356JpXjxvLJNZcvGdr+qpsoTmp+YUJjMX/KVDptvNGSxx032pDyyVNrj5k6jbuO+zYALdu3p99hX+XTj+Y1aJ1q3lbVEB4OEBH9U0qTamzvCvyoXqsqlYlvE903hK49oawFhS8OJL36n9pjui+dNohtdoaZVWe/0bXn0pNrunQnem4Es6ej+lH55usUNupN9NoQWrSg5f5fpuK5J5cO+Hg+8w/fn/knHML8Ew6hcuyrS5pIWreBNm0AKNtpN6ispDjh3dK8EKmRqXzzdcqW+WwtHvnU0gEfz6f8sP0oP/5gyo8/uOqzVd1E1vxstdhp96q15n626s2U0S/S5QtbsN6mvSm0bMnWRx/B2w88XGtM2/W7Ljnh6Utnn8mYm5ZNPrRGIhr21gitNJFMKU0EiIjbI+JmYBjQBjgX2Bl4tEEqbEjFIsU7/0jZqT+HQoHiqH/BtA8oHHwCaeJ40mv/pTDwEKLfDlBZQVo4n8q/XglAbLk1hQPOh8oKSIni7dfCx+WlfDXNW7GST666jHaXXUOUFVj00L0U33+X1ieeQuW4sVTU/MW3jOjchXbDqtawplkzWXjpeQ1YuFZk6C030HffvejQbX0u/eAN7r/gEkbecHOpy1o3FStZ+Ltf0n7YH6BQqFoK8v47tP7OKVS+tbrPVlfaD7sGUpE0awYL/GzVq1RZyaP/cw7H3X8nUVbGmJtGMOuNNxl4/rlMffElxj/wML333qvqTO2UmPjsc/zzzLOXfP03/vUA6/ftQ8sO7Tlt/Gs8+P0zeO9fj5fwFakpipRWPfMcEe2By6g66aYjVRO5l6WU6rTwpSlNba/rFrz2QalLUB2d88Q7pS5Bn8Nl+67g8jlqlK4Z5TKXpuLchbNLHtE1dI/T4nf3lfw1L6suFzpcDCwE2lKVSL5X1yZSkiRJzVddGsnnqWokdwEGAsdHxB31WpUkSVJj5xrJOv2JxKEppc/+xtVUYEhEfLMea5IkSVITsNpGskYTWXObq+AlSdK6zT+FXKepbUmSJGk5NpKSJEnKUpc1kpIkSVpWIz0BpiGZSEqSJCmLiaQkSVIOE0kTSUmSJOUxkZQkScphImkiKUmSpDwmkpIkSTm8ILmJpCRJkvKYSEqSJOVwjaSJpCRJkvKYSEqSJOUwkTSRlCRJUh4TSUmSpBwmkiaSkiRJymMiKUmSlMPrSJpISpIkKY+NpCRJkrI4tS1JkpTDk21MJCVJkpTHRFKSJCmHiaSJpCRJkvKYSEqSJOUwkTSRlCRJUh4TSUmSpAzhBclNJCVJkpTHRFKSJCmHayRNJCVJkpTHRFKSJCmHiaSJpCRJkvKYSEqSJOUwkTSRlCRJUh4TSUmSpBxeR9JEUpIkSXlsJCVJkpTFqW1JkqQcnmxjIilJkqQ8JpKSJEk5TCRNJCVJkpTHRFKSJCmHiaSJpCRJkvKYSEqSJOXwguQmkpIkScpjIilJkpTDNZL130jGsSfW91NoLen0y0GlLkF1dNkh+5S6BH0O/+/Jd0tdgupocJd2pS5BalJMJCVJknKYSLpGUpIkSXlsJCVJknIUCg17W42IGBwRb0XE+Ij48Qr2nxURYyNiTEQ8FhGbrvFbsKbfQJIkSaUVEWXA1cBXgP7A8RHRf5lhLwE7p5S2A+4Ehq3p89pISpIk5Yho2Nuq7QqMTym9m1JaBNwKDKk5IKX0REppQfXDUcDGa/oW2EhKkiQ1ARFxUkSMrnE7qcbujYAPajyeVL1tZYYCD61pTZ61LUmS1ASklIYDw9f0+0TEN4CdgTW+lpyNpCRJUo7GdfmfycAmNR5vXL2tlog4APgpsE9K6dM1fVKntiVJkpq+54E+EbF5RLQCjgPuqzkgInYE/gh8LaU0Y208qYmkJElSjkaUSKaUKiLidOARoAy4IaX0ekRcBIxOKd0H/AroANwRVbVPTCl9bU2e10ZSkiSpGUgpPQg8uMy2n9W4f8Dafk4bSUmSpBx1uEh4c+c7IEmSpCwmkpIkSTka0RrJUjGRlCRJUhYTSUmSpBwmkiaSkiRJymMiKUmSlCPM43wHJEmSlMVEUpIkKUfBNZImkpIkScpiIilJkpTDNZImkpIkScpjIylJkqQsTm1LkiTl8ILkJpKSJEnKYyIpSZKUo2Ae5zsgSZKkLCaSkiRJOVwjaSIpSZKkPCaSkiRJObwguYmkJEmS8phISpIk5XCNpImkJEmS8phISpIk5fA6kiaSkiRJymMiKUmSlMM1kiaSkiRJymMiKUmSlMPrSJpISpIkKY+NpCRJkrI4tS1JkpSj4Mk2JpKSJEnKYiIpSZKUw5NtTCQlSZKUx0RSkiQphxckN5GUJElSHhNJSZKkHK6RNJGUJElSHhNJSZKkHF5H0kZyWSklLrnlfp5+9S3atmrFJUOPov+mGy037vX3J/OT6+/gk8WL2XtAP35ywleJCH51+4M8+fKbtGxRxibdu/KLoUfRqV3bErySdUNKiV8Mu4Kn/j2SNm3a8MsLf8Y2W2+13Lihp53BzJmzqKysZKcdd+CCc8+hrKyMhx79F7+/9jreee997rj5zwzYpn8JXsW6ocUue9Dm9HOgrMDiB+7m07/9ecXj9h5E+wuvYP7JJ1A5biy0aEHbs86nrF9/SEUWXvUrKl8Z3cDV6zPfvP5qBhw6mPIZM7l4wO6lLmed12PQfgy45GKirIwJN4/g7d/+vtb+bX9xId332hOAsrZtad29Gw9s3g+A/hecR6+DDgDgrct/w+S7723Y4tUsfK6p7Yi4pL4KaSyefvUtJkz/kIcv/REXfvtwLvzLPSscd9HN93DRiUfw8KU/YsL0D3nm1XEA7NH/C9x78Q+556Ifslmvblz3wJMNV/w66OlnR/L+xA/4571/5+LzzuXnl1y2wnG/vewS7rv9Fv5x563MmTOXhx99DIC+W27JVVcMY5cv7tiQZa97CgXa/PBcPv7xacw/8QhaDhpMYdMtlh/Xth2tjziBirFjlmxqdeiRAMwfejQf/+j7tD31LM+ULKHnbhzBVYOPKHUZAigU2H7YpTx3zAk89qW92fjIw+nYr2+tIa/99AKe2OcAntjnAN697gam/ONBAHoeeACdtx/AE3sP4qkDD+YLp51Ci44dSvEqmraIhr01QittJCPid8vcrgJO/exxA9bYoB5/6Q2G7LEjEcH2W/amfMEnzJw7r9aYmXPnMX/hp2y/ZW8igiF77MhjL40FYM9t+9KirAyA7bfozbQ5HzX4a1iXPPbU0xx26MFEBDtsN4B55eXMmDlruXEdOlT9gKyoqGRxxWKi+gO55Rabs8VmmzZozeuisq22pTjlA9LUyVBRweLHH6HlnvsuN67Nd0/j01tvhEWLlmwrbLoFFS/9F4A0dw5pfjll/bZpoMq1rPHPjGTB7DmlLkNAl512ZP5777FgwkTS4sVMuuseen3lyysdv9GRhzHp73cD0HGrvnw4chSpspLKBQuYN3YsPQbt31ClqxlZVSJ5ONAVGA28UP3fxdX3X6j/0kpjxpyP6NW185LHPbuux/Q5tRvJ6XPm0bNLp1pjZqygYbzr2dEMHNCv3moVTJ8xg169ei553KtnD6bPmLHCsUNP/QF7DPoy7du148sH+AOzIUW3HqQZ05Y8Ls6cTnTrUWtMoc9WFHr0pGLUM7W2V74zjpZ77AuFMqLXhpT17U/06Im0rmu7wQYsnDxlyeNPpkyl7QYbrHjsxhvTvndvZj79LAAfvfY6PQbtR1nbtrTq2pVue+1Ju402bJC6m5UoNOytEVpVVf2BWcBg4NGU0k1AeUrppur7KxURJ0XE6IgYfd29/1yL5TYd197/BGWFAl/dfYdSl6Jq119zFc8++iCLFi1m1POusWtUImh76o9YeM2vl9u1+MF7KM6cToc/3kLb08+m4rVXoLJYgiKlpmvjIw5jyn3/gGLVZ2fmE08x/dHH2Pvh+9n5T39g9vOjSZWVJa5STdFKT7ZJKZUDZ0bEF4EREfEAdVxTmVIaDgwHqPz3XWltFFqfbnnsOe54+nkABmy+MdNmz12yb/rsj2qljwA9u3SqlVJOn/0RPbqst+Tx3c++wFNj3uCGH31vyRSq1p4Rt93B7XfdA8CAbfozbdr0JfumTZ9Bzx49VvKV0Lp1awbtuzePPfk0e+6+W32Xqmpp1gyiR68ljwvde5Jm1UiO27WnsPmWdLjyTwBE1/Vp94srWfDTM6kcN5ZPrrl8ydD2V91EcdKEBqtdaqwWTp1K2xopYpsNN2Dh1KkrHLvREUMYc865tbaN+/VvGffr3wKw0/BrmD/+3fortrnyrO06NYafAPsDC4FnASJi3/orqeGdMOhL3H3hGdx94RkM2rE/9458iZQSr7wzkY7t2tC9c+1GsnvnTnRo25pX3plISol7R77E/jtuDcAzr77F9Q89zdU/+BZtW7cqxctp9r5+7NHce9sI7r1tBAfstw/3/ONBUkq8POZVOnboQI/u3WqN/3jBgiXrJisqKnjy2X+7LrKBVb75OmUb9SZ6bQgtWtBy/y+zeORTSwd8PJ/yw/aj/PiDKT/+YCrHvrqkiaR1G2jTBoAWO+0OlRUUJ/gLT5r74st02GIL2vXuTbRsycZHHMa0h5efBezQ5wu06tyZ2f+tMRNTKNCySxcAOvXfmvW26c+MJ55soMrVnNTl8j+3A38BfgX8ufqkm52BL9VnYaWy93b9eHrMWwz+8eW0adWSX3z3qCX7Dr/gd9x94RkAnP+NIfzkhjv5dNFiBg7oy97VayH/b8R9LF5cydArbgBg+y034effOrzhX8g6Yp+99uSpZ0dy4NeOoG2bNlzy8/OX7Bty7Ne597YRLFy4kFPO/F8WLV5MKhbZbeedOO6oqrNOH338CS6+7Apmz5nDyWecxdb9+nD9NVeV6uU0X8VKFv7ul7Qf9gcoFFj80L0U33+H1t85hcq3xlJRs6lcRnTuSvth10AqkmbNYMGl5zVg4VrW0FtuoO++e9Gh2/pc+sEb3H/BJYy84eZSl7VOSpWVjDnnJ+xx59+qLv8z4m+Uv/kWW517DnNfenlJU7nxEYcxqXoW5zOFli0Z+GDV5X4qyst54eTTnNpWlkhp1TPPEdEeuAzYCegIjAAuSynVaZFSU5jaVpWyHQeVugTV0UeH7FPqEvQ5/L8nTVCbisFd2pW6BNXRYbOnlXxeufLuqxq0xyk7/Aclf83LqsvU9mKqprXbAm2A9+raREqSJKn5qksj+TxVjeQuwEDg+Ii4o16rkiRJauy8IHmd1kgOTSl9tkJ3KjAkIr5ZjzVJkiSpCVhtI1mjiay5zZXVkiRp3dZILxLekHwHJEmSlKUuU9uSJElalhckN5GUJElSHhNJSZKkHK6RNJGUJElSHhNJSZKkHI302o4NyURSkiRJWUwkJUmSchTM43wHJEmSlMVEUpIkKYdrJE0kJUmSlMdGUpIkSVmc2pYkScrhBclNJCVJkpTHRFKSJCmHJ9uYSEqSJCmPiaQkSVIOL0huIilJkqQ8JpKSJEk5XCNpIilJkqQ8JpKSJEk5vI6kiaQkSZLy2EhKkiTliGjY22rLicER8VZEjI+IH69gf+uIuK16/38iYrM1fQtsJCVJkpq4iCgDrga+AvQHjo+I/ssMGwrMSSl9AfgNcNmaPq+NpCRJUo4oNOxt1XYFxqeU3k0pLQJuBYYsM2YIcFP1/TuBQRFrduq5jaQkSVITEBEnRcToGreTauzeCPigxuNJ1dtY0ZiUUgXwEbD+mtTkWduSJEk5Cg17HcmU0nBgeIM+6WqYSEqSJDV9k4FNajzeuHrbCsdERAtgPeDDNXlSG0lJkqSm73mgT0RsHhGtgOOA+5YZcx/w7er7RwGPp5TSmjypU9uSJEk5GtEFyVNKFRFxOvAIUAbckFJ6PSIuAkanlO4DrgdujojxwGyqms01YiMpSZLUDKSUHgQeXGbbz2rc/wQ4em0+p42kJElSjjW7ck6z0HgyWUmSJDUpJpKSJEk5GtEayVLxHZAkSVIWE0lJkqQMa/jXBZsFE0lJkiRlMZGUJEnK4RpJE0lJkiTlMZGUJEnKYSJpIilJkqQ8JpKSJEk5Cp61bSIpSZKkLCaSkiRJOVwjaSIpSZKkPPWfSD79SL0/hdaOyscfKHUJqqNrRk0sdQn6HAZ3aVfqElRHD89ZUOoSVEeHlboAAU5tS5Ik5fFPJDq1LUmSpDwmkpIkSTk82cZEUpIkSXlMJCVJknK4RtJEUpIkSXlMJCVJknK4RtJEUpIkSXlMJCVJknIUXCNpIilJkqQsJpKSJEk5XCNpIilJkqQ8JpKSJEk5vI6kiaQkSZLymEhKkiTlcI2kiaQkSZLymEhKkiTlcI2kiaQkSZLy2EhKkiQpi1PbkiRJOTzZxkRSkiRJeUwkJUmSchTM43wHJEmSlMVEUpIkKUN4+R8TSUmSJOUxkZQkScrhWdsmkpIkScpjIilJkpTDNZImkpIkScpjIilJkpTDNZImkpIkScpjIilJkpTDNZImkpIkScpjIilJkpTDv7VtIilJkqQ8NpKSJEnK4tS2JElSDk+2MZGUJElSHhNJSZKkHF6Q3ERSkiRJeUwkJUmScrhG0kRSkiRJeUwkJUmSsphImkhKkiQpi4mkJElSDtdImkhKkiQpj4mkJElSDhNJE0lJkiTlMZGUJEnKYiJpI7msLbahcMAxUCiQXn6WNOqRWrtjlwOIHfaEYhEWzKf4wE0wbzZ06krhyFOqYu5CGemFJ0gvPV2iF7GO2HJbCl8+HiJILz1DGvlQrd2x20HEjgOhWFl1rO7/M3z04dIBrdpQOOVi0lsvkR6+pYGLX/dsceAgDrj8EgplZbx8482Muvy3tfZ36r0xh1x7Fe26dWPhnDnc/93vUz55CgDH3nsHG+66M5NGjuKOI48vRfnrlB6D9mPAJRcTZWVMuHkEb//297X2b/uLC+m+154AlLVtS+vu3Xhg834A9L/gPHoddAAAb13+GybffW/DFq8lvnn91Qw4dDDlM2Zy8YDdS12OmikbyZoiKBx0PMVbr4R5cyiceC7p7THw4dQlQ9L0iaQ/PwUVi4kd9yb2O5J073Uw/yOKf7kMKiugZWsK3/sZ6e1XYP5HpXs9zVkEhcFfpzjiiqpj9b3zSeNehlk1jtW0CaQ/PQkVi4id9iUGHUW6649Lv8W+h5Mmjmvw0tdFUShw0JXDuPWQI5g3eQonPvsYb//jYT58860lY/a/9GJeG3Ebr464lU33Gci+F53P/UNPAWDUb66iZbu27Dj0xBK9gnVIocD2wy7l30ccw8IpU9n3sYeZ9vA/KX9r6WfltZ9esOT+Fv/fUNbbblsAeh54AJ23H8ATew+i0Lo1e913F9P/9RgV5fMb/GUInrtxBE/+fjgn/uWPqx+sPK6RdI1kLRtuDnNmwNxZUKwkvTGa6Lt97TETx0HFYgDSlPeITp2rthcrq5pIgBYt/EPu9W3DLWofq9f/S/TbsfaYCW9BxSIA0uR3iU5dlu7rtSl06ATvjG3AotddG+6yE3PeeY+570+guHgxb9xxF30P/UqtMd226sf7Tz0DwISnnqHPoQcv2TfhyadZZDPSILrstCPz33uPBRMmkhYvZtJd99DrK19e6fiNjjyMSX+/G4COW/Xlw5GjSJWVVC5YwLyxY+kxaP+GKl3LGP/MSBbMnlPqMtTMrbbbiYgfRESX1Y1rFjp0Js2r8aErnwMdO690eGy/J+md15du6NiFwtDzKZz2y6opcdPI+tOpM2ne7KWP563mWO2wF2n8a589onDgMaRHb6/XErVUhw03YN6kyUsel0+eQseNNqg1Zsarr9FvyKEA9B1yKK07daRt13XjR09j0naDDVhYvaQA4JMpU2m7wQYrHrvxxrTv3ZuZTz8LwEevvU6PQftR1rYtrbp2pdtee9Juow0bpG5JpVGX2Kwn8HxE3B4RgyNWn+NGxEkRMToiRl/33zfWvMpGKLbZjei1Kek//1y6sXwOxesvpnjtecSA3aFdx9IVqCViwO7EBpuRnnu46vHO+5HGv1r1DwU1Go+f+zN6D9yD7zz3JL0H7sm8yVMoVlaWuiytwsZHHMaU+/5RtWYcmPnEU0x/9DH2fvh+dv7TH5j9/GiSx1DNWTTwrRFa7RrJlNJ5EXE+cBDwHeD3EXE7cH1K6Z2VfM1wYDhA5aUnp7VYb/2aP5fo1IUlBXfsAuVzlx+32VbEHl+pWp/32XR2re/zEWnmFNikD7z1Yj0WvA6bN5fo1HXpseq0kmO1+dbEXodQvGnY0mO18ZZE7z7EzvtBq9ZQ1gIWfUp6/O8NVPy6Z/6UqXTaeKMljztutCHlk6fWHjN1Gncd920AWrZvT7/DvsqnH81r0DoFC6dOpW2NFLHNhhuwcOrUFY7d6IghjDnn3Frbxv36t4z7ddWJVDsNv4b549+tv2IllVydFvKllBIwrfpWAXQB7oyIYfVYW8Ob8j506QHrrQ+FMmLrnatOmKmp5yYUBn+D4p3XwILypds7doYWLavut2lHbPIFmD2toSpf90x5D7r2hM7dqo7VNrtWnWxTU6/eFA7+FsXbrqp1rNI911H83TkUr/p/pEfvII0ZaRNZz6aMfpEuX9iC9TbtTaFlS7Y++gjefuDhWmPart91ycL1L519JmNuGlGKUtd5c198mQ5bbEG73r2Jli3Z+IjDmPbwP5cb16HPF2jVuTOz/zt66cZCgZZdqpYjdOq/Nett058ZTzzZQJVLpWAkudpEMiJ+CHwLmAX8CTg7pbQ4IgrA28A59VtiA0pFio/eSuG4H0IUSGP+DbOmEgO/Spo6AcaPobDfkdCqNYXDT6r6mnmzq5rK9TegMOgoSKnqcjT/eRRmTln18ylfKlJ8eASFE/6n6li98izMnELsM4Q09X0Y9wqFQUdXHasjq878Zd7sqqZSDS5VVvLo/5zDcfffSZSVMeamEcx6400Gnn8uU198ifEPPEzvvfdi34vOh5SY+Oxz/PPMs5d8/Tf+9QDr9+1Dyw7tOW38azz4/TN471+Pl/AVNV+pspIx5/yEPe78W9Xlf0b8jfI332Krc89h7ksvL2kqNz7iMCbddU+try20bMnAB6su91NRXs4LJ5/m1HYJDb3lBvruuxcduq3PpR+8wf0XXMLIG24udVlqZqIqbFzFgIgLgRtSShNWsG/rlNIqF0E2qantdV3FCqbp1SgNu+TuUpegz2Hrtq1KXYLq6OE5C0pdguro2jSv5BFdmvp2g/Y4sUGfkr/mZdVljeQFq9jXPM+kkSRJ0mp5sUNJkqQcEQ17W6NSo2tEPBoRb1f/d7nrq0XEDhHxXES8HhFjIuLY1X1fG0lJkqTm78fAYymlPsBj1Y+XtQD4VkppG2AwcGVEdF7VN7WRlCRJytKkztoeAtxUff8m4LBlB6SUxqWU3q6+PwWYAXRf1Te1kZQkSWoCav7Bl+rbSZ/jy3umlD67KOw0qv7gzKqea1egFbDCa4Z/ZrUn20iSJGkF1nDd4udV8w++rEhE/AvotYJdP13m+6SIWOkZ5xGxAXAz8O2UUnFVNdlISpIkNQMppQNWti8ipkfEBimlqdWN4oyVjOsEPAD8NKU0anXP6dS2JElSlia1RvI+4NvV978N3Lvcq4loBdwN/CWldGddvqmNpCRJUvP3S+DAiHgbOKD6MRGxc0T8qXrMMcDewIkR8XL1bYdVfVOntiVJknI08BrJNZFS+hAYtILto4HvVd//K/DXz/N9TSQlSZKUxUZSkiRJWZzaliRJytGEprbri4mkJEmSsphISpIkZTGRNJGUJElSFhNJSZKkDOEaSRNJSZIk5TGRlCRJymEiaSIpSZKkPCaSkiRJWUwkTSQlSZKUxURSkiQph2skTSQlSZKUx0RSkiQph4mkiaQkSZLymEhKkiRlMZE0kZQkSVIWG0lJkiRlcWpbkiQphyfbmEhKkiQpj4mkJElSDgNJE0lJkiTlMZGUJEnKYiRpIilJkqQsJpKSJEk5PGvbRFKSJEl5TCQlSZJymEiaSEqSJCmPiaQkSVIWE0kTSUmSJGUxkZQkScrhGkkTSUmSJOUxkZQkScphImkiKUmSpDw2kpIkScri1LYkSVIWp7ZNJCVJkpTFRFKSJCmHJ9uYSEqSJClPpJRKXUOTFBEnpZSGl7oOrZ7HqunwWDUdHqumw2Ol+mQime+kUhegOvNYNR0eq6bDY9V0eKxUb2wkJUmSlMVGUpIkSVlsJPO53qTp8Fg1HR6rpsNj1XR4rFRvPNlGkiRJWUwkJUmSlMVGUpIkSVlsJDNFxMMRMTci/lHqWrRyEbFDRDwXEa9HxJiIOLbUNWnFImLTiHgxIl6uPl7fL3VNWrWI6BQRkyLi96WuRVJpuEYyU0QMAtoBJ6eUDi11PVqxiOgLpJTS2xGxIfACsHVKaW5pK9OyIqIVVT+TPo2IDsBrwB4ppSklLk0rERG/BboDs1NKp5e6HkkNz0RyNSJil+okq01EtK9OSrZNKT0GlJe6Pi21omMFtEopvQ1Q3ZDMoOoXn0poJceqb0rp0+ohrfHnU6Owsp+BEbET0BP4Z6lr1IpFxEURcWaNx7+IiB+WsCQ1Qy1KXUBjl1J6PiLuA/4PaAv8NaX0WonL0gqs7lhFxK5AK+CdEpWoais7VhGxCfAA8AXgbNPI0lvRsQLGAo8D3wAOKGF5WrUbgLuAKyOiABwH7FraktTc2EjWzUXA88AnwBklrkWrtsJjFREbADcD304pFUtUm2pb7lillD4AtqtehnBPRNyZUppewhpVZdljdSrwYEppUkSUtDCtXErp/Yj4MCJ2pCo9fiml9GGp61LzYiNZN+sDHYCWQBvg49KWo1VY7lhFRCeqUq6fppRGlbI41bLSz1VKaUpEvAYMBO4sTXmqYdlj9SVgYEScWr29VUTMTyn9uIQ1asX+BJwI9KIqoZTWKk+2qYPqaZ1bgc2BDT5bVB4R+wI/8mSbxmPZYwWcBTwE3J9SurKEpWkZKzhWvwQ+TCktjIguwH+AI1NKr5awTLHyn4HV+04EdvZkm8ap+iS2V6n6R0CflFJliUtSM2MiuRoR8S1gcUrplogoA0ZGxP7AhcBWQIeImAQMTSk9Uspa13UrOlZUrQnaG1i/+hcewIkppZdLU6VgpcdqG+BXEZGAAC63iSy9lf0MTCk9XuratHoppUUR8QQw1yZS9cFEUpKkZqr6JJsXgaM/u4KFtDZ5eQ1JkpqhiOgPjAces4lUfTGRlCRJUhYTSUmSJGWxkZQkSVIWG0lJkiRlsZGUJElSFhtJSZIkZfn/ARPs0IH34IjyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = X_y_df.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266edef6-e134-4145-9ab2-7cc21419c886",
   "metadata": {},
   "source": [
    "## How to select the best k features using pearsons correlation\n",
    "Use sklearns r_regression, which looks at the correlation between the predictors and the target and selects the most positive and negative correlations\n",
    "\n",
    "You must fit the selector on the training set and transform the training and testing sets with your selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0afe286d-62f1-4f61-b0f1-bd6a75a5f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import r_regression\n",
    "k_in = 2\n",
    "\n",
    "training_set_x = X[:5]\n",
    "training_set_y = y[:5]\n",
    "\n",
    "testing_set_x = X[5:]\n",
    "testing_set_y = y[5:]\n",
    "\n",
    "selector = SelectKBest(r_regression, k=k_in).fit(training_set_x, training_set_y)\n",
    "training_set_new = selector.transform(training_set_x)\n",
    "testing_set_new = selector.transform(testing_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74b77f-82ec-442d-921b-478db7c20072",
   "metadata": {},
   "source": [
    "This is the new training set after selection (as you can see it has removed a feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22101467-d172-478c-b358-d4838297eb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  4  8\n",
       "1  3  4\n",
       "2  9  9\n",
       "3  4  4\n",
       "4  3  4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(training_set_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b938b-9d37-4e9e-b21c-60c4990d8093",
   "metadata": {},
   "source": [
    "This is the new testing set after selection (as you can see it has removed a feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b29585-db24-4732-9716-9607ab941f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  7  4\n",
       "1  6  4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testing_set_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba7eda2-cc47-43ff-98d5-5c350f4b3b0a",
   "metadata": {},
   "source": [
    "### How to show which features were selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad43e75-4853-4b9b-a40a-a14302d77929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x4', 'x3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "selector.scores_\n",
    "top_n = np.argsort(selector.scores_)[-k_in:]\n",
    "print(X_y_df.iloc[:, top_n].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93e670-c734-49a4-bf63-4457cc42f60b",
   "metadata": {},
   "source": [
    "## How to do forward selection with tol of 0.01 for mean squared error\n",
    "\n",
    "Note: SequentialFeatureSelector also allows setting the number of features you want, however for this lab we will be using the \"auto\" method with the criteria of \"To add in a feature, it must reduce our mse by 0.01\"\n",
    "\n",
    "You must fit the selector on the training set and transform the training and testing sets with your selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66902e11-e3d6-4e43-9d6c-78ec143cb515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(reg, n_features_to_select=\"auto\", scoring='neg_mean_squared_error', tol=0.01, direction='forward')\n",
    "sfs.fit(training_set_x, training_set_y)\n",
    "training_set_x_new = sfs.transform(training_set_x)\n",
    "testing_set_x_new = sfs.transform(testing_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b6b12-c907-4710-84ae-2d317039a6d6",
   "metadata": {},
   "source": [
    "**n_features_to_select**: This is the number of features you want to select<br>\n",
    "**scoring**: refers to the metric we want to use for our tolerance criteria. Here we are using mean squared error<br>\n",
    "**direction**: this denotes whether we are doing forward or backward selection<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3dd60-db0a-4a58-95c9-3e44e4898a9f",
   "metadata": {},
   "source": [
    "### How to show which features were selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f38832c4-b992-4c53-b005-a2d8bc5406fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x2', 'x3', 'x4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fs_indices = sfs.get_support(True)\n",
    "print(X_y_df.iloc[:, fs_indices].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466edab7-8fb0-41ba-a68d-050671a19116",
   "metadata": {},
   "source": [
    "## How to do backward selection with tol of 0.01 for mean squared error\n",
    "\n",
    "Same thing as forward just set direction to backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e3e872-6ca2-4fce-9866-28915fba3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(reg, n_features_to_select=\"auto\", scoring='neg_mean_squared_error', tol=0.01, direction='backward')\n",
    "sfs.fit(training_set_x, training_set_y)\n",
    "training_set_x_new = sfs.transform(training_set_x)\n",
    "testing_set_x_new = sfs.transform(testing_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469431bf-7fb0-4ef3-9b8b-8b79d98c2135",
   "metadata": {},
   "source": [
    "**n_features_to_select**: This is the number of features you want to select\n",
    "**scoring**: refers to the metric we want to use for our tolerance criteria. Here we are using mean squared error<br>\n",
    "**direction**: this denotes whether we are doing forward or backward selection<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef857a-fe15-48f2-b161-6a02fe76cd79",
   "metadata": {},
   "source": [
    "### How to show which features were selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a6d0d1-dbd2-43bb-89a5-5cfa6e3ef84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x2', 'x3', 'x4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fs_indices = sfs.get_support(True)\n",
    "print(X_y_df.iloc[:, fs_indices].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9c717-2b20-460f-9d50-7e5cf9efbd4a",
   "metadata": {},
   "source": [
    "## How to do recursive feature elimination\n",
    "\n",
    "It follows almost the same convention as the others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3524fa20-c3d7-4607-acb2-2783a84aea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=3, step=1)\n",
    "selector.fit(training_set_x, training_set_y)\n",
    "\n",
    "training_set_x_new = selector.transform(training_set_x)\n",
    "testing_set_x_new = selector.transform(testing_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce66b3e-b1a6-4aeb-a9a3-868e183e553f",
   "metadata": {},
   "source": [
    "**n_features_to_select**: This is the number of features you want to select<br>\n",
    "**step**:  step corresponds to the (integer) number of features to remove at each iteration. (Just leave at 1 for this Lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f671af4-fc8d-4b7b-90a3-80e533c0866e",
   "metadata": {},
   "source": [
    "### How to show which features were selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a273aa06-43e0-460e-bcc8-4c1ac98a2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x2', 'x3', 'x4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "fs_indices = selector.get_support(True)\n",
    "print(X_y_df.iloc[:, fs_indices].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64dd6c-a903-4b49-b224-0f0a38b0d11a",
   "metadata": {},
   "source": [
    "### How to show ranking of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfddbfb0-76ee-4cf1-b8c1-12450e2d531d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  features  rank\n",
       "0       x1     2\n",
       "1       x2     1\n",
       "2       x3     1\n",
       "3       x4     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ranking_indices = selector.ranking_\n",
    "pd.DataFrame(list(zip(X_y_df.columns,ranking_indices)), columns=[\"features\",\"rank\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045e644-4d09-4882-bc79-aaea5a72db98",
   "metadata": {},
   "source": [
    "As you might have noticed, all the selected features have ranking of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0d7d9-8866-477b-baa6-aaac533ed952",
   "metadata": {},
   "source": [
    "## How to do cross validation with ShuffleSplit\n",
    "\n",
    "We split the data into 4 training sets and 4 testing sets.<br>\n",
    "The indices for the samples used for each dataset are printed below.<br>\n",
    "In your objectives, you are asked to get the mse and rsquared for every testing set.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb019f17-367e-4a02-85a6-f1124e9488b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1 3 0 5 4] TEST: [6 2]\n",
      "TRAIN: [6 3 4 2 5] TEST: [1 0]\n",
      "TRAIN: [5 1 2 4 0] TEST: [6 3]\n",
      "TRAIN: [3 4 1 0 6] TEST: [5 2]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "rs = ShuffleSplit(n_splits=4, test_size=.25, random_state=0)\n",
    "\n",
    "for train_index, test_index in rs.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc3ca1-141e-4e09-b93e-0b551a22df6d",
   "metadata": {},
   "source": [
    "***n_splits***: number of train and test splits for the dataset <br>\n",
    "***test_size***: what percentage of samples should the testing set get from the dataset <br>\n",
    "***random_state***: seed the random generator to make your results reproducible <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835394ee-f178-4521-88c4-12bb8c661b98",
   "metadata": {},
   "source": [
    "## How to use ***RidgeCV*** to find the best regularization ***parameter/alpha***\n",
    "\n",
    "RidgeCV performs cross validaion using regularized linear regression to find the best alpha for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20021ae0-2bff-4c55-b36b-5ab3bf3ffc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "reg_cv = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(training_set_x, training_set_y)\n",
    "alpha = reg_cv.alpha_\n",
    "print(f\"alpha: {alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86bbe7-c469-4882-84bc-9c3c90488e22",
   "metadata": {},
   "source": [
    "As you can see above, we passed a list of alphas to see which alpha the algorithm believes is best after cross validating on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0917b1c-5c07-4fee-b78b-73a031184141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([93.99890687, 80.00316107])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_cv.predict(testing_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f76d2-57cf-4d68-84d2-3b9df1c2aab9",
   "metadata": {},
   "source": [
    "We can predict using RidgeCV and it will use that alpha for a prediction using Regularized Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4396d-db1e-4534-bf16-9ff828ad8094",
   "metadata": {},
   "source": [
    "## How to use Regularized Linear Regression/Ridge Regression\n",
    "\n",
    "This is normal RidgeRegression where no cross validfation is done, we just pass it a single alpha.<br>\n",
    "Lets use the alpha we got from RidgeCV. The results should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ad0baf-e7b3-40a3-b162-b85204ad31ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([93.99890687, 80.00316107])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "reg = Ridge(alpha=alpha).fit(training_set_x, training_set_y)\n",
    "reg.predict(testing_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b3687-ae5f-434b-9bf6-1e7edad57da6",
   "metadata": {},
   "source": [
    "## How to plot a Learning curve\n",
    "\n",
    "Below I am showing you my implementation for plotting a learning curve.\n",
    " - I am using a dictionary to store my training samples and mse for every iteration\n",
    " - I am slicing up to the iterating value because I want to grab 1 sample on the first run, 2 on the second run... m on the m'th run\n",
    " - I use my Ridge regressor to predict at each step. Note: I have to reshape the training_set and testing_set when i==1 because the Ridge regressor      will crash otherwise\n",
    " - I get my mse and store it in the appropriate key i.e: 1 - for 1 sample, 2 - for 2 samples.... m - for m samples\n",
    " - I then plot both my training and testing mse against the number of samples to get my learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fd80089-1613-4c1e-9604-06f1dd9ba8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "holder_m_mse_train = {}\n",
    "holder_m_mse_test = {}\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "for i in range(1, len(training_set_x)+1):\n",
    "    if i == 1:\n",
    "        reg_cv = Ridge(alpha=alpha).fit(training_set_x[:i,:].reshape(1, -1), training_set_y[:i])\n",
    "        train_mse = mean_squared_error(training_set_y[:i].reshape(1, -1), reg_cv.predict(training_set_x[:i,:].reshape(1, -1)))\n",
    "        test_mse = mean_squared_error(testing_set_y, reg_cv.predict(testing_set_x))\n",
    "\n",
    "    else:\n",
    "        reg_cv = Ridge(alpha=alpha).fit(training_set_x[:i,:], training_set_y[:i])\n",
    "        train_mse = mean_squared_error(training_set_y[:i], reg_cv.predict(training_set_x[:i,:]))\n",
    "        test_mse = mean_squared_error(testing_set_y, reg_cv.predict(testing_set_x))\n",
    "        \n",
    "    holder_m_mse_train[i] = train_mse\n",
    "    holder_m_mse_test[i] = test_mse\n",
    "\n",
    "lists_train = sorted(holder_m_mse_train.items()) # sorted by key, return a list of tuples\n",
    "lists_test = sorted(holder_m_mse_test.items())\n",
    "\n",
    "x_train, y_train = zip(*lists_train) # unpack a list of pairs into two tuples\n",
    "x_test, y_test = zip(*lists_test)\n",
    "\n",
    "plt.plot(x_train, y_train, color=\"blue\")\n",
    "plt.plot(x_test, y_test, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7d812-318b-429f-90b0-7d17b5e99b7b",
   "metadata": {},
   "source": [
    "## How to do LassoCV Regression\n",
    "\n",
    "LassoCV Regression works very similarly to RidgeCV Regression.\n",
    " - You give it a list of alphas and it picks the one that maximizes its cross validation criteria on the dataset given\n",
    " - Of course unlike Ridghe regression it forces features it has deemed unimportant to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48d948ea-e394-4fcb-91b1-ab06b6d26479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([93.70929912, 81.26263722])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso_cv = LassoCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(training_set_x, training_set_y)\n",
    "lasso_cv.predict(testing_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc8bed-6d01-41e5-9a6e-1ee4d8ed9f75",
   "metadata": {},
   "source": [
    "You can get the selected aplha the same way as with Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "248271aa-e757-4bf6-907c-740893c3d58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = lasso_cv.alpha_\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac90d1-1865-471e-b04c-a25c1f958eca",
   "metadata": {},
   "source": [
    "With LassoCV or regular Lasso Regression it is possible to get the features that the algorithm has not set to 0.(Those are the selected features)<br>\n",
    "\n",
    "### How to get features that Lasso Selected \n",
    "This can be done by getting the values that are not 0 from the coefficients/weights that Lasso provides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a19cd69-0960-425e-8367-6dfc45a1e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x2', 'x3', 'x4'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_indices = np.nonzero(lasso_cv.coef_)\n",
    "print(X_y_df.iloc[:, lasso_indices[0]].columns)\n",
    "lasso_indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca6e9b-dece-46d5-8ce8-750770ff8c7a",
   "metadata": {},
   "source": [
    "## How to do regular Lasso Regression\n",
    "Below I am showing you how to fit and predict with regular Lasso Regression. We will just use the selected alpha we got from LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd4990c2-dd97-4145-892e-a3706bd325bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([93.70929912, 81.26263722])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso= Lasso(alpha=alpha).fit(training_set_x, training_set_y)\n",
    "lasso.predict(testing_set_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3e896-5815-4a6d-b467-59f4f7d5ed15",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "You will be using the ***Iris dataset*** from sklearn for all your classification tasks\n",
    "\n",
    "Get the dataset with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79d627d9-de92-4303-a705-b890216607ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_df =  load_iris(as_frame=True).frame\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57aeb3-795d-4ffc-95c4-b64cf26fa0dd",
   "metadata": {},
   "source": [
    "Your objectives are available in the README.md file accompanying this notebook:\n",
    "\n",
    "I will be providing a jupyter file with headers for where you can insert your answers for each question\n",
    "\n",
    "Below we will be going over the following to help you with the Lab:\n",
    "\n",
    "- How to use MinMaxScaler for **feature scaling**\n",
    "- How to use ***Chisquare*** for feature selection\n",
    "- Notes about ***forward selection*** and ***backward selection*** for classification\n",
    "- How to do ***cross validation*** with ***StratifiedShuffleSplit***\n",
    "- How to do ***LogisticRegressionCV*** to find the best alpha for regularization on the dataset\n",
    "  - How to grab the apha it selected\n",
    "- How to get ***log_loss***\n",
    "\n",
    "\n",
    "***Note:*** Remember to set 'penalty' to 'none' for the ***Multinomial Logistic Regression*** part of the lab and to 'l2' for the ***Regularized Logistic Regression*** part<br>\n",
    "***Note:*** **Recursive feature elimination** works the same way for classification as regression so I will not be going over it again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431da121-47f6-4dc7-bf16-0dcaa41eae63",
   "metadata": {},
   "source": [
    "## Below is our sample data for our demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e68ccc01-40ca-48f3-beb8-372a77f89f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2  x3  x4  x5  y\n",
       "0   -1  -1   1   5   7  0\n",
       "1   -2  -1   0   9   8  0\n",
       "2    1   1   3   6   4  1\n",
       "3    2   1   3   4   6  1\n",
       "4   -2  -1   0   6   8  0\n",
       "5   -2  -9   0   3   7  1\n",
       "6   -2  -4   0   7   7  1\n",
       "7   -5  -1   0   5   8  1\n",
       "8   -2  -1   0   3   7  0\n",
       "9   -2  -1   7   3   7  0\n",
       "10  -4  -1   5   3   9  0\n",
       "11   1   2   6   7   9  1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[-1, -1, 1, 5, 7], [-2, -1, 0, 9, 8], [1, 1, 3, 6, 4], [2, 1, 3, 4, 6], [-2, -1, 0, 6, 8], [-2, -9, 0, 3, 7],[-2, -4, 0, 7, 7], [-5, -1, 0, 5, 8], [-2, -1, 0, 3, 7], [-2, -1, 7, 3, 7], [-4, -1, 5, 3, 9], [1, 2, 6, 7, 9]])\n",
    "Y = np.array([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1])\n",
    "X_y_df = pd.DataFrame(np.array(np.transpose([X[:,0], X[:,1],X[:,2], X[:,3], X[:,4], Y])), columns=[\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"y\"])\n",
    "X_y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c34cff-f2fe-4200-9717-2b96075615bd",
   "metadata": {},
   "source": [
    "## How to use MinMaxScaler for feature scaling\n",
    "\n",
    "A few Notes:\n",
    "- Feature scaling will likely not have a huge effect on the Iris datase but we are doing it because, if the dateset was much larger or complex, lbfgs might not converge and you would need to feature scale to help it converge. \n",
    "- We are using MinMaxScaler instead of StandardScaler for feature scaling because it gives the range [0,1] by default. When trying to feature select on chisquare, all your values must be positive so this feature scaling helps us acheive that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b1190a5-af55-4339-af66-4007b9aa36ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "training_set_x = X[:10]\n",
    "training_set_y = Y[:10]\n",
    "\n",
    "testing_set_x = X[10:]\n",
    "testing_set_y = Y[10:]\n",
    "\n",
    "scaler.fit(training_set_x)\n",
    "training_set_x_fs = scaler.transform(training_set_x)\n",
    "testing_set_x_fs = scaler.transform(testing_set_x)\n",
    "\n",
    "# Scaling full dataset of features(training and testing together)\n",
    "all_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05474ec4-27ab-45f3-810b-6511feff1556",
   "metadata": {},
   "source": [
    "## How to use Chisquare for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cce919b7-1eb9-4024-874f-9dc03e5ddd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "k_in=2\n",
    "selector = SelectKBest(chi2, k=k_in).fit(training_set_x_fs, training_set_y)\n",
    "training_set_x_fs_new = selector.transform(training_set_x_fs)\n",
    "testing_set_x_fs_new = selector.transform(testing_set_x_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba7364-d876-4b6e-92ae-4e1e58c543d7",
   "metadata": {},
   "source": [
    "***k***: This is the number of features to grab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6ec0d-ff6f-4af8-bb60-ec432a4351d9",
   "metadata": {},
   "source": [
    "#### How to show which features were selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f42a51df-97a7-4042-b537-cf49cab2cc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x2', 'x5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "selector.scores_\n",
    "top_n = np.argsort(selector.scores_)[-k_in:]\n",
    "print(X_y_df.iloc[:, top_n].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32d1cf-a3f1-444f-bdb7-4fa420a9ddb0",
   "metadata": {},
   "source": [
    "## Notes about forward and backward selection for classification.\n",
    "\n",
    "The only difference when using it for classification vs regression is the model we give it is of course LogisticRegression and the scoring is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "805a571d-7ae9-422a-a71b-485b2479c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', penalty='l2')\n",
    "sfs = SequentialFeatureSelector(clf, n_features_to_select=\"auto\", scoring='accuracy', tol=0.01, direction='forward')\n",
    "sfs.fit(training_set_x_fs, training_set_y)\n",
    "training_set_x_new = sfs.transform(training_set_x_fs)\n",
    "testing_set_x_new = sfs.transform(testing_set_x_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e750f3d-176e-434c-8b9e-fede8935dcd6",
   "metadata": {},
   "source": [
    "## How to do cross validation with StratifiedShuffleSplit\n",
    "\n",
    "We are Using StratifiedShuffle split because it is good practice to shuffle your data before creating your datasets and also we want to make sure we have a balace of classes in our train and test sets\n",
    "\n",
    "We split the data into 4 training sets and 4 testing sets.<br>\n",
    "The indices for the samples used for each dataset are printed below.<br>\n",
    "In your objectives, you are asked to get the log loss and accuracy for every testing set.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a6ca0ad-cac2-4983-8533-eeae9bd7f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 7 8 6 9 4 1 3 5] TEST: [11  0 10]\n",
      "TRAIN: [ 8  1 11 10  4  3  6  7  0] TEST: [2 5 9]\n",
      "TRAIN: [10  4  2  1  3  0  6  5 11] TEST: [9 8 7]\n",
      "TRAIN: [ 7  5  8  4  1  2  9  3 10] TEST: [11  6  0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=4, test_size=.25, random_state=0)\n",
    "\n",
    "for train_index, test_index in sss.split(all_scaled, Y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = all_scaled[train_index], all_scaled[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4044de-f447-4cb9-a17f-740a9017ba39",
   "metadata": {},
   "source": [
    "## How to do LogisticRegressionCV to find the best alpha per class for regularization on the dataset\n",
    "\n",
    "Note: Since our sample data is binary, it, only one alpha is returned. However on multiclass problems, then multiple alphas are returned; one for each class. These alphas gave us the best scores accross each class for the cross validation done internally\n",
    "\n",
    "LogisticRegressionCV follows the same convention as the other scikitlearn classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9954031-4131-4b12-b70f-b5cb403cd26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf_cv = LogisticRegressionCV(Cs=[1e-3, 1e-2, 1e-1, 1], random_state=0, solver='lbfgs', penalty='l2').fit(training_set_x_fs, training_set_y)\n",
    "alpha_per_class = clf_cv.C_\n",
    "print(alpha_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daedd69-d970-477b-bcdb-2ae77c1962f3",
   "metadata": {},
   "source": [
    "Below is how you predict using LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08ecd05d-c305-4a34-8bcd-3889a40ef4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cv.predict(testing_set_x_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a56b5b-6959-4907-9f88-922ce645c06c",
   "metadata": {},
   "source": [
    "## How to get log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f527d05-87af-48a4-b941-a43aa29c9575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931537256697817"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss_g = log_loss(testing_set_y, clf_cv.predict_proba(testing_set_x_fs))\n",
    "log_loss_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c5988-13a4-448e-bb77-f787516d8523",
   "metadata": {},
   "source": [
    "Notice that we are giving it the probabilities of our predictions rather than the actual predictions using the function \"predict_proba\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0d1ab-2206-46de-8568-6f0aea040d99",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- Did the features selected by r_regression and the correlation matrix match up and make sense to you?\n",
    "- Did you notice that when using auto forward selection you ended up with less features than with backward     \n",
    "  elimination?\n",
    "- How different were the features you got accross different feature selection techniques\n",
    "- When you used Cross validation with RidgeCV, LassoCV and LogisticRegressionCV, did you notice that one alpha was chosen for most of the created datasets. Did that alpha line up with the alpha selected when you didnt use Cross Validation?\n",
    "- Did your learning curve look like the ones we discussed in class?\n",
    "\n",
    "Note: These are not questions that need to be answered for marks. They are things I want you to keep in mind and reflect on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
